#!/usr/bin/env python3
# -*- coding: utf-8 -*-
###########################################
# (c) 2016-2020 Polyvios Pratikakis
# polyvios@ics.forth.gr
###########################################

"""
Use wget to crawl all shortened URLs for the specified user bio or
tweets, or all users, and populate the shorturl collection.
"""

import optparse
import pymongo
from progress.bar import Bar
import pipes, shlex, subprocess
from subprocess import Popen, PIPE
from twkit.utils import *

def deshorten_url(db, url):
  if isinstance(url, (bytes,bytearray)):
    url = url.decode('utf-8')
  if (  '://t.co' not in url
    and '://ift.tt' not in url
    and '://bit.ly' not in url
    and '://amzn.to' not in url
    and '://x2t.com' not in url
    and '://goo.gl' not in url
    and '://ow.ly' not in url
    and '://ht.ly' not in url
    and '://tinyurl.com' not in url
    and '://tr.im' not in url
    and '://lnked.in' not in url
    and '://eepurl.com' not in url
    and '://dlvr.it' not in url
    and '://lnkd.in' not in url
    and '://ln.is' not in url
    and '://gph.is' not in url
    and '://buff.ly' not in url
    and '://reut.rs' not in url
    and '://nyti.ms' not in url
    and '://rol.st' not in url
    and '://ind.pn' not in url
    and '://wp.me' not in url
    and '://fb.me' not in url
    and '://ig.me' not in url
    and '://is.gd' not in url
    and '://g.co' not in url
    and '://instagr.am' not in url
    and '://trib.al' not in url
    and '://econ.trib.al' not in url
    and '://youtu.be' not in url
    and '://shar.es' not in url
    and '://n.mynews.ly' not in url
    and '://oak.ctx.ly' not in url
    and '://j.mp' not in url
    and '://econ.st' not in url
    and '://www.linkedin.com/slink?code=' not in url
    and '://sml.lnk.to' not in url
    and '://go.shr.lc' not in url
    #and '://feeds.feedburner.com/~r' not in url
    #and '://smarturl.it' not in url
  ):
    return url

  cached = db.shorturl.find_one({'shorturl': url})
  if cached is not None:
    if cached['url'] is None:
      return None
      #pass
    else:
      if url != cached['url']:
        return deshorten_url(db, cached['url'])

  args = u'wget -t 1 --user-agent=Firefox --timeout=5 --spider -S {} 2>&1 | grep Location | head -n 1'.format(pipes.quote(url))
  p = Popen(args, shell=True, stdout=PIPE)
  output = str(p.communicate()[0], 'utf-8').strip()
  if verbose(): print(output)
  locstrs = output.split()
  if verbose(): print(output.split())
  if len(locstrs) >= 2:
    out_url = locstrs[1]
  #try:
    if len(out_url):
      print(u'{} -> {}'.format(url, out_url))
      db.shorturl.update_one(
        {'shorturl': url},
        {'$set': {'shorturl': url, 'url': out_url}},
        upsert=True)
      return deshorten_url(db, out_url)
  #except Exception as e:
  else:
    print(u'bad location: "{}" for url "{}"'.format(output, url))
  db.shorturl.update_one(
    {'shorturl': url},
    {'$set': {'shorturl': url, 'url': None}},
    upsert=True)
  return url

if __name__ == '__main__':
  parser = optparse.OptionParser()
  parser.add_option('-v', '--verbose', action='store_true', dest='verbose', default=False, help='Make noise.')
  parser.add_option('-t', '--tweets', action='store_true', dest='tweets', default=False, help='Look up and resolve urls in tweets.')
  parser.add_option('-u', '--user', action='store', dest='user', default=None, help='Only handle urls for the given user.')
  parser.add_option("-f", "--force", action="store_true", dest="force", default=False, help="Rescan anyway.")
  parser.add_option('--id', action='store_true', dest='ids', default=False, help='Input is user id.')
  parser.add_option("--skip", action="store", dest="skip", type="int", default=0, help="Restart from index")
  parser.add_option("--stopafter", action="store", dest="stopafter", type="int", default=0, help="Stop after scanning how many")
  (options, args) = parser.parse_args()

  verbose(options.verbose)
  db, api = init_state(use_cache=False, ignore_api=True)

  if options.user:
    u = lookup_user(db, uid=int(options.user)) if options.ids else lookup_user(db, uname=options.user)
    if u is None:
      print(u'unknown user', options.user)
      sys.exit(1)
    if verbose():
      print(u'Scanning user {}/{}'.format(u['id'], u['screen_name_lower']))
  if options.tweets:
    if options.user:
      if options.force:
        cursor = db.tweets.find({'user.id': u['id'], 'urls': {'$ne': None}}).batch_size(2)
      else:
        cursor = db.tweets.find({'user.id': u['id'], 'urls': {'$ne': None}, 'deshorten': None}).batch_size(2)
    else:
      cursor = db.tweets.find({'urls': {'$ne': None}, 'deshorten': None}).batch_size(2)
    if options.skip:
      cursor = cursor.skip(options.skip)
    count = db.tweets.count()
    if options.stopafter:
      cursor = cursor.limit(options.stopafter)
      count = options.stopafter
    if verbose():
      cursor = Bar('Loading:', max=count, suffix = '%(index)d/%(max)d - %(eta_td)s').iter(cursor)
    for t in cursor:
      out_urls = []
      if 'urls' not in t or t['urls'] is None: continue
      for url in t['urls']:
        try:
          out_url = deshorten_url(db, url)
        except pymongo.errors.WriteError:
          continue
        if out_url:
          out_urls.append(out_url)
      db.tweets.update_one({'id': t['id']}, {'$set': {'deshorten': True}})
      #if len(out_urls):
        #db.tweets.update_one({'id': t['id']}, {'$set': {'urls': out_urls}})
  else:
    if options.user:
      cursor = db.users.find({'id': u['id'], 'url': {'$ne': None}}).batch_size(10)
    else:
      cursor = db.users.find({'url': {'$ne': None}}).batch_size(10)
    cnt = cursor.count()
    if verbose():
      cursor = Bar('Loading:', max=cnt, suffix = '%(index)d/%(max)d - %(eta_td)s').iter(cursor)
    print(u'Found {}'.format(cnt))
    for u in cursor:
      url = u['url']
      out_url = deshorten_url(db, url)
      #if out_url:
        #db.users.update_one(u, {'$set': {'url': out_url}})

